\chapter{Introduction}\label{introduction}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Context: What is Scala.js
\item
  Relevance: importance of networking for Scala.js
\item
  Motivation: Many JS APIs

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    Websocket
  \item
    Comet
  \item
    WebRTC
  \end{itemize}
\item
  Motivation: Many network programing models

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    Akka
  \item
    RPC (type safe)
  \item
    Steams (scalaz, akka-stream)
  \end{itemize}
\item
  Plan/Contributions
\end{itemize}

\chapter{Transport}\label{transport}

\TODO{This section, scala-js-transport library, main contribution}

\section{A Uniform Interface}\label{a-uniform-interface}

We begin our discussion by the definition of an interface for
asynchronous transports, presented in \autoref{transportInterface}. This
interface aims at \emph{transparently} modeling the different underlying
technologies, meaning that is simply delegates tasks to the actual
implementation, without adding new functionalities. Thanks to support of
\emph{futures} and \emph{promises} in Scala.js, these interfaces cross
compile to both Java bytecode and JavaScript.

\transportInterface{Definition of the core networking interfaces.}

A \emph{Transport} can both \emph{listen} for incoming connections and
\emph{connect} to remote \emph{Transports}. Platforms limited to act
either as client or server will return a failed \emph{future} for either
of these methods. In order to listen for incoming connections, the user
of a \emph{Transport} has to complete the promise returned by the
\emph{listen} method with a \emph{ConnectionListener}. To keep the
definition generic, \emph{Address} is an abstract type. As we will see
later, it varies greatly from one technology to another.

\emph{ConnectionHandle} represents an opened connection. Thereby, it
supports four type of interactions: writing a message, listening for
incoming messages, closing the connection and listening for connection
closure. Similarly to \emph{Transport}, listening for incoming messages
is achieved by completing a promise of \emph{MessageListener}.

An example of direct usage of the \emph{Transport} interface is
presented in \autoref{rawclient}. This example implements a simple
WebSocket client that sends a "Hello World!" message to a WebSocket echo
server. After instantiating the \emph{Transport} and declaring the
\emph{Address} of the server, \emph{transport.connect} initiate the
WebSocket connection and returns a \emph{future} of
\emph{ConnectionHandle}. This is \emph{future} will be successfully
completed upon connection establishment, or result in a failure if an
error occurred during the process. In the successful case, the callback
is given a \emph{ConnectionHandle} object, which is used to \emph{write}
the "Hello World!" message, handle incoming messages and \emph{close}
the connection.

\rawclient{Example of WebSocket client implementation.}

The WebSocket echo server used in \autoref{rawclient} has a very simple
behavior: received messages are immediately sent back to their author.
\autoref{rawserver} shows a possible implementation of an echo server
with the \emph{Transport} interface. The body of this example is wrapped
in a \emph{try-finally} block to ensure the proper shutdown of the
server once the program terminate. In order to listen for incoming
connections, one must use \emph{transport.listen()} which returns a
\emph{future} connection listener \emph{promise}. If the underlying
implementation is able \emph{listen} for new WebSocket connections on
the given address and port, the \emph{future} will be successful, and
the \emph{promise} can then be completed with a connection listener.

\rawserver{Implementation of a WebSocket echo server.}

In addition to the example of usage presented in
\autoref{transportInterface} and \autoref{rawclient}, the
scala-js-transport library provides two additional abstractions to
express communication over the network. \autoref{wrappers} contains
examples of implementations using remote procedure calls and the actor
model, which are available as wrappers around the \emph{Transport} to
prover higher level of abstraction.

\section{Implementations}\label{implementations}

The scala-js-transport library contains several implementations of
\emph{Transports} for WebSocket, SockJS \cite{sockjs} and WebRTC
\cite{webrtc2014}. This subsection briefly presents the different
technologies and their respective advantages. \autoref{impl-summary}
summarizes the available \emph{Transports} for each platform and
technology.

\begin{longtable}[c]{@{}lccc@{}}
\caption{Summary of the available
Transports.\label{impl-summary}}\tabularnewline
\toprule
Platform & WebSocket & SockJS & WebRTC\tabularnewline
\midrule
\endfirsthead
\toprule
Platform & WebSocket & SockJS & WebRTC\tabularnewline
\midrule
\endhead
JavaScript & client & client & client\tabularnewline
Play Framework & server & server & -\tabularnewline
Netty & both & - & -\tabularnewline
Tyrus & client & - & -\tabularnewline
\bottomrule
\end{longtable}

\subsection{WebSocket}\label{websocket}

WebSocket provides full-duplex communication over a single TCP
connection. Connection establishment begin with an HTTP request from
client to server. After the handshake is completed, the TCP connection
used for the initial HTTP request is \emph{upgraded} to change protocol,
and kept open to become the actual WebSocket connection. This mechanism
allows WebSocket to be wildly supported over different network
configurations.

WebSocket is also well supported across different platforms. Our library
provides four WebSocket \emph{Transports}, a native JavaScript client, a
Play Framework server, a Netty client/server and a Tyrus client. While
having all three Play, Netty and Tyrus might seem redundant, each of
them comes with its own advantages. Play is a complete web framework,
suitable to build every component of a web application. Play is based on
Netty, which means that for a standalone WebSocket server, using Netty
directly leads to better performances and less dependencies. Regarding
client side, the Tyrus library offers a standalone WebSocket client
which is lightweight compared to the Netty framework.

\subsection{SockJS}\label{sockjs}

SockJS \cite{sockjs} is a WebSocket emulation protocol which fallbacks
to different protocols when WebSocket is not supported. Is supports a
large number of techniques to emulate the sending of messages from
server to client, such as AJAX long polling, AJAX streaming, EventSource
and streaming content by slowly loading an HTML file in an iframe. These
techniques are based on the following idea: by issuing a regular HTTP
request from client to server, and voluntarily delaying the response
from the server, the server side can decide when to release information.
This allows to emulate the sending of messages from server to client
which not supported in the traditional request-response communication
model.

The scala-js-transport library provides a \emph{Transport} build on the
official SockJS JavaScript client, and a server on the Play Framework
via a community plugin \cite{play2-sockjs}. Netty developers have
scheduled SockJS support for the next major release.

\subsection{WebRTC}\label{webrtc}

WebRTC \cite{webrtc2014} is an experimental API for peer to peer
communication between web browsers. Initially targeted at audio and
video communication, WebRTC also provides \emph{Data Channels} to
communicate arbitrary data. Contrary to WebSocket only supports TCP,
WebRTC can be configures to use either TCP, UDP or SCTP.

As opposed to WebSocket and SockJS which only need a URL to establish a
connection, WebRTC requires a \emph{signaling channel} in order to open
the peer to peer connection. The \emph{signaling channel} is not tight
to a particular technology, its only requirement is to allow a back an
forth communication between peers. This is commonly achieved by
connecting both peers via WebSocket to a server, which then acts as a
relay for the WebRTC connection establishment.

To simplify the process of relaying messages from one peer to another,
our library uses picklers for \emph{ConnectionHandle}. Concretely, when
a \emph{ConnectionHandle} object connecting node \emph{A} and \emph{B}
is sent by \emph{B} over an already established connection with
\emph{C}, the \emph{ConnectionHandle} received by \emph{C} will act as a
connection between \emph{A} and \emph{C}, hiding the fact that \emph{B}
relays messages between the two nodes.

The scala-js-transport library provides two \emph{Transports} for
WebRTC, \emph{WebRTCClient} and \emph{WebRTCClientFallback}. The later
implements some additional logic to detect WebRTC support, and
automatically fall back to using the signaling channel as substitute for
WebRTC if either peer does not support it.

At the time of writing, WebRTC is implemented is Chrome, Firefox and
Opera, and lakes support in Safari and Internet Explorer. The only non
browser implementations are available on the node.js platform.

\TODO{Add a sequence diagram and explain connection establishment.}\\

\section{Wrappers}\label{wrappers}

By using \emph{Transport} interface, it is possible write programs with
an abstract communication medium. We present two \emph{Transport}
wrappers, for Akka and Autowire~\cite{autowire}, which allow to work
with different model of concurrency. Because Autowire and Akka (via
\cite{scala-js-actors}) can both be used on the JVM and on JavaScript,
these wrappers can be used to build cross compiling programs compatible
with all the \emph{Transport} implementations presented in
\autoref{implementations}.

\subsection{Akka}\label{akka}

The actor model is based on asynchronous message passing between
primitive entities called actors. Featuring both location transparency
and fault tolerance via supervision, the actor model is particularly
adapted to distributed environment. Akka, a toolkit build around the
actor model for the JVM, was partly ported to Scala.js by S. Doeraene in
\cite{scala-js-actors}. The communication interface implemented in
\cite{scala-js-actors} was revisited into the \emph{Transport} wrapper
presented in \autoref{actorWrapper}.

\actorWrapper{Transport wrappers to handle connections with actors.}

The two methods \emph{acceptWithActor} and \emph{connectWithActor} use
the underlying \emph{listen} and \emph{connect} methods of the wrapped
\emph{Transport}, and create an \emph{handler} actor to handle the
connection. The semantic is as follows: the \emph{handler} actor is
given an \emph{ActorRef} in it is constructor, to which sending messages
results in sending outgoing messages thought the connection, and
messages received by the \emph{handler} actor are incoming messages
received from the connection. Furthermore, the life span of an
\emph{handler} actor is tight to life span of its connection, meaning
that the \emph{preStart} and \emph{postStop} hooks can be used to detect
the creation and the termination of the connection, and killing the
\emph{handler} actor results in closing the connection.
\autoref{yellingActor} shows an example of a simple \emph{handler} actor
which than sending back whatever it receives in uppercase.

\yellingActor{Example of a connection handling actor.}

Thanks to the picking mechanism developed in \cite{scala-js-actors}, it
is possible to sent messages of any type thought a connection, given
that implicit picklers for these types of messages have been registered.
Out of the box, picklers for case classes and case objects can be
macros-generated by the pickling library. In addition, an
\emph{ActorRef} pickler allows the transmission of \emph{ActorRefs}
thought a connection, making them transparently usable from the side of
the connection as if they were references to local actors.

\subsection{Autowire}\label{autowire}

Remote procedure call allow remote systems to communicate through an
interface similar to method calls. The Autowire library allows to
perform type-safe, reflection-free remote procedure calls between Scala
system. It uses macros and is agnostic of both the transport-mechanism
and the serialization library.

The scala-js-transport library offers a \emph{RpcWrapper}, which makes
internal use of Autowire to provide remote provide call on top of any of
the available \emph{Transports}. Because the \emph{Transport} interface
communicates with \emph{Strings}, the \emph{RpcWrapper} is able to set
all the type parameters of Autowire, as well embedding the uPickle
serialization library \cite{upickle}, thus trading flexibility to reduce
boilerplate. \autoref{rpcExample} shows a complete remote procedure call
implementation on top of WebSocket.

\rpcExample{Example of remote procedure call implementation.}

The main strength of remote procedure calls are their simplicity and
type-safety. Indeed, because of how similar remote procedure calls are
to actual method calls, they require little learning for the programmer.
In addition, consistency between client and server side can be verified
at compile time, and integrated development environment functionalities
such as \emph{refactoring} and \emph{go to definition} work out of the
box. However, this simplicity also comes with some draw backs. Contrary
to the actor model which explicitly models the life span of connections,
and different failure scenarios, this is not build in when using remote
procedure calls. In order to implement fine grain error handling and
recovery mechanism on top of remote procedure calls, one would have to
work at a lower lever than the one offered by the model itself, that is
with the \emph{Transport} interface in our case.

\section{Going further}\label{going-further}

The different \emph{Transport} implementations and wrappers presented is
this section allows for several interesting combinations. Because the
scala-js-transport library is built around a central communication
interface, it is easily expendable in both directions. Any new
implementation of the \emph{Transport} interface with for a different
platform or technology would immediately be usable with all the
wrappers. Analogously, any new \emph{Transport} wrapper would
automatically be compatible with the variety of available
implementations.

All the implementations and wrappers are accompanied by integration
tests. These tests are built using the \emph{Selenium WebDriver} to
check proper behavior of the library using real web browsers. Our tests
for WebRTC use two browsers, wich can be configured to be run with two
different browsers to test their compatibility.

\chapter{Dealing with latency}\label{dealing-with-latency}

\TODO{This section, the framework, the game}

\section{Latency Compensation}\label{latency-compensation}

Working with distributed systems introduces numerous challenges compared
the development of single machine applications. Much of the complexity
comes from the communication links; limited throughput, risk of failure,
and latency all have to be taken into consideration when information is
transfered from one machine to another. Our discussion will be focused
on issues related to latency.

When talking about latency sensitive application, the first examples
coming to mind might be multiplayer video games. In order to provide a
fun and immersive experience, real-time games have to \emph{feel}
responsive, the must offer sensations and interactions similar to the
one experienced by a tennis player when he caches the ball, or of a
Formula One driver when he drives his car at full speed. . Techniques to
compensate network latency also have uses in online
communication/collaboration tools such as \emph{Google Docs}, where
remote users can work on the same document as if they where sitting next
to each other. Essentially, any application where a shared state can be
simultaneously mutated by different peers is confronted to issues
related to latency.

While little information is available about the most recent games and
collaborative applications, the literature contains some insightful
material about the theoretical aspects of latency compensation.
According to \cite{timelines2013}, the different techniques can be
divided into three categories: predictive techniques, delayed input
techniques and time-offsettings techniques.

\emph{Predictive techniques} estimate the current value of the global
state using information available locally. These techniques are
traditionally implemented using a central authoritative server which
gathers inputs from all clients, computes the value of global state, and
broadcasts this state back to all clients. It then possible to do
prediction on the client side by computing a "throwaway" state using the
latest local inputs, which is later replaced by the state provided by
the server as soon as it is received. Predictions techniques with a
centralized server managing the application state are used in most
\emph{First person shooter} games, including recent titles built with
the Source Engine \cite{source-engine}. Predictions are sometimes
limited to certain type of objects and interactions, such as in the
\emph{dead reckoning} \cite{ieee-dead-reckoning1995} technique that
estimate the current positions of moving objects based on their earlier
position, velocity and acceleration information.

\emph{Delayed input techniques} defer the execution of all actions to
allow simultaneous execution by all peers. This solution is typically
used in application where the state, (or the variations of state) is too
large to be frequently sent over the network. In this case, peers would
directly exchange the user inputs and simultaneously simulate
application with a fixed delay. Having a centralized server is not
mandatory, and peer to peer configurations might be favored because of
the reduce communication latency. Very often, the perceived latency can
be diminished by instantly emitting a purely visual or sonorous feedback
as soon as the an input is entered, but delaying the actual effects of
the action to have it executed simultaneously on all peers. The
classical \emph{Age of Empires} series uses this techniques with a fixed
delay of 500 ms, and supports up to 8 players and 1600 independently
controllable entities \cite{aoe}.

\emph{Time-offsettings techniques} add a delay in the application of
remote inputs. Different peers will then see different versions of the
application state over time. Local perception filters
\cite{local-perception-filter1998} are an example of such techniques
where the amount of delayed applied to world entities is proportional to
their distance to the peer avatar. As a result, a user can interact in
real time with entities spatially close to him, and see the interaction
at a distance \emph{as if} they where appending in real time. The most
important limitation of local perception filters is that peers avatar
have to be kept at a minimum distance from each other, and can only
interact by exchanging passive entities, such as bullets or arrows
\cite{smed2006}. Indeed, passed a certain proximity threshold, the time
distortion becomes smaller than the network latency which invalidates
the model.

Each technique comes with its own advantages and disadvantages, and are
essentially making different tradeoffs between consistency and
responsiveness. Without going into further details on the different
latency compensation techniques, this introduction should give the
reader an idea of the variety of possible solutions and their respective
sophistication.

\section{A Functional Framework}\label{a-functional-framework}

We now present scala-lag-comp, a Scala framework for predictive latency
compensation. The framework cross compiles to run on both Java virtual
machines and JavaScript engines, allowing to build applications
targeting both platforms which can transparently collaborate.

By imposing a purely functional design to its users, scala-lag-comp
focuses on correctness and leaves very little room for runtime errors.
It implements predictive latency compensation in a fully distributed
fashion. As opposed to the traditional architectures for prediction
techniques, such as the one described in~\cite{source-engine}, our
framework does uses any authoritative node to hold the global state of
the application, and can therefore functions in peer to peer, without
single points of failure.

To do so, each peer runs a local simulation of the application up to the
current time, using all the information available locally. Whenever an
input is transmitted to a peer via the network, this remote input will
necessarily be slightly out of date when it arrives at destination. In
order to incorporate this out of date input into the local simulation,
the framework \emph{rolls back} the state of the simulation as it was
just before the time of emission of this remote input, and then replays
the simulation up to the current time. \autoref{stateGraph} shows this
process in action from the point of view of peer \emph{P1}. In this
example, \emph{P1} emits an input at time \emph{t2}. Then, at time
\emph{t3}, \emph{P1} receives an input from \emph{P2} which was emitted
at time \emph{t1}. At this point, the framework invalidates a branch of
the state tree, \emph{S2-S3}, and computes \emph{S2'-S3'-S4'} to take
into account both inputs.

\stateGraph{Growth of the state graph over time, from the point of view of \emph{P1}.}

By instantaneously applying local input, the application reactiveness is
not affected by the quality of the connection; a user interacts with the
application as he would if he was the only peer involved. This property
comes with the price of having short periods of inconsistencies between
the different peers. These inconsistencies last until all peers are
aware of all inputs, at which point the simulation recovers its global
unity.

By nature, this design requires a careful management of the application
state and it evolutions over time. Indeed, even a small variation
between two remote simulations can cause a divergence, and result in
out-of-sync application states. \cite{aoe}~reports out-of-sync issues as
one of the main difficulty they encountered during the development of
multiplayer features. In our case, the \emph{roll back in time}
procedure introduces another source of potential mistake. Any mutation
in a branch of the simulation that would not properly be canceled when
rolling back to a previous state would induce serious bugs, of the hard
to isolate and hard to reproduce kind.

To cope with these issues, the scala-lag-comp framework takes entirely
care of state management and imposes a functional programming style to
its users. \autoref{engineInterface} defines the unique interface
exposed by the framework: \emph{Engine}.

\engineInterface{Interface of the latency compensation framework.}

An application is entirely defined by its \emph{initialState}, a
\emph{nextState} function that given a \emph{State} and some
\emph{Actions} emitted during a time unit computer the \emph{State} at
the next time unit, and a \emph{render} function to display
\emph{States} to the users. \emph{State} objects must be immutable, and
\emph{nextState} has to be a pure function. User \emph{Inputs} are
transmitted to an \emph{Engine} via \emph{futureAct}, and
\emph{triggerRendering} should be called whenever the platform is ready
to display the current \emph{State}, at most every 1/60th of seconds.
Finally, an \emph{Engine} excepts a \emph{broadcastConnection} to
communicate with all the participating peers.

\section{Architecture and
Implementation}\label{architecture-and-implementation}

We now give a quick overview of the architecture and implementation of
the scala-lag-comp framework. The \emph{Engine} interface presented in
\autoref{a-functional-framework} is composed of two stateful components:
\emph{ClockSync} and \emph{StateLoop}. \emph{ClockSync} is responsible
for the initial attribution of peer \emph{identity}, and the
establishment of a \emph{globalTime}, synchronized among all peers.
\emph{StateLoop} stores all the peer \emph{Inputs} and is able to
predict the application for the \emph{Inputs} received so far.
\autoref{lagcompEngine} shows the interconnection between the components
of an \emph{Engine}. The \emph{triggerRendering} function of
\emph{Engine} gets the current \emph{globalTime} from the
\emph{ClockSync}, ask the \emph{StateLoop} to predict the \emph{State}
at that time, and passes the output to the user via the \emph{render}
function. Wherever an \emph{Input} is sent to the \emph{Engine} via
\emph{futureAct}, this \emph{Input} is combined with the peer
\emph{identity} to form an \emph{Action}, then couples with the
\emph{globalTime} to form an \emph{Event}. This \emph{Event} is directly
transmitted to the local \emph{StateLoop}, and sent via the connection
to the remote \emph{StateLoops}.

\lagcompEngine{Overview the architecture of the latency compensation framework.}

\subsection{ClockSync}\label{clocksync}

The first action undertaken by the \emph{ClockSync} component is to send
a \emph{Greeting} message in broadcast, and listen for other
\emph{Greetings} message during a small time window. Peer membership and
identity are determined from these messages. Each \emph{Greeting}
message contains a randomly generated number which is used to order
peers globally, and attribute them a consistent identity.

Once peers are all aware of each other, they need to agree on a
\emph{globalTime}. Ultimately, each peer holds a difference of time
\dt between it's internal clock and the globally consented clock. The
global clock is defined to be the arithmetic average of all the peer's
clock. In order to compute their \dt, each pair of peers needs exchange
their clock values. This is accomplished in a way similar to Cristian's
algorithm~\cite{cristian89}. Firstly, peers send request for the clock
values of other peers. Upon receiving a response containing a time
\emph{t}, one can estimate the value of the remote clock by adding half
of the request round trip time to \emph{t}. One all peers have
estimations of the various clocks, they are able to locally compute the
average, and use it as the estimated \emph{globalTime}. To minimize the
impact of network variations, several requests are emitted between each
pair of peers, and the algorithms only retains the requests with the
shortest round trip times.

Certainly, this approach will result in slightly shifted views of the
\emph{globalTime}. Even with more solutions elaborated, such as the
Network Time Protocol, the average precision varies between 20 ms and
100 ms depending on the quality of the connection \cite{mills2010}. In
the case of the scala-lag-comp framework, out-of-sync clocks can
decrease the quality of the user experience but do not effect
correctness. Indeed, once every user has seen every input, and once all
the simulations have reached the \emph{globalTime} at which the latest
input was issued, all the simulations generate \emph{States} for the
same \emph{globalTime}. If one user is significantly ahead of the
others, this will have the effect of preventing him to react quickly to
other peers actions. Suppose a peers \(P_a\) think the \emph{globalTime}
is \(t_a\) seconds ahead of what other peers believe. Whenever he
receives an input issued at time \(t_1\), \(P_a\) will have already
simulated and displayed the application up to time
\(t_1 + t_a + networkdelay\), and his reaction to this input will be
issued with a lag of \(t_a + networkdelay\). Furthermore, being ahead of
the actual \emph{globalTime} implies that the \emph{rolls back}
mechanism will be used for significant portions of time, introducing
potential visual glitches such as avatars teleporting from one point to
another.

To prevent malicious manipulations of the clock (a form of cheating in
games), one could improve the framework by adding a mechanism to verify
that the issue times of inputs respects some causal consistency. Follows
an example of such mechanism.

Suppose that every message \(m_i\) sent contains a random number
\(r_i\). Then, newly emitted inputs could include the latest random
number generated locally, and the latest random number received from
other peers. Adding this information would allow the detection of
malicious peers. Indeed, if a malicious peer \emph{P1} pretends that his
message \(m_1\) is issued one second later that it is in reality, and
\emph{P2} sends a message \(m_2\) that can by estimated to arrive before
\(m_1\) was issues, then \emph{P2} can detect that \emph{P1} is
malicious by checking that \(m_1\) does not contain \(r_2\).Similarly,
pretending that a message is issued in the past would break the sequence
of "latest random number generated locally", and thus be detectable.

\subsection{StateLoop}\label{stateloop}

The \emph{StateLoop} component implements the heart of the prediction
algorithm: a \emph{stateAt} function which given a \emph{time}, computes
a prediction of the application \emph{State}. To do so, \emph{StateLoop}
maintains a set of user \emph{Actions} received so far, which is used to
simulate the execution of the application. \emph{Actions} are stored in
an immutable list of \emph{Events} (pair of \emph{Input} and time),
sorted by time.

Semantically, every call to the the \emph{stateAt} function implies a
recursive computation of the current state. This recursion starts from
the \emph{initialState}, and successively applies the \emph{nextState}
function with the appropriate \emph{Events} for each time unit until the
process reaches the current time.

Doing the complete recursion on every frame would be too expansive.
However, since this process uses a pure function, called
\emph{computeState} and returning a \emph{State} given a time and list
of \emph{Events} happening before that time, it can be made efficient
using memoization. Indeed, In the most common case when \emph{stateAt}
is called and no new \emph{Events} have been received since the last
call, the cache hits right away, after a single recursion step. Whenever
a remote input is received and inserted into the sorted list of
\emph{Events}, the recursion takes place up to the time at which this
newly received \emph{Event} was issued. The cache will then hit at that
point, from where \emph{nextState} is successively applies to obtain the
\emph{State} for the current time. This is how the \emph{rolls back}
mechanism illustrated in \autoref{stateGraph} is implemented in a time
efficient manner.

Regarding memory management, timing assumptions on the network allow the
use of a bounded cache. Indeed, if we consider a peer to be disconnected
when one of his messages takes more than one second to transit over the
network, it is sufficient to retain history of \emph{States} for a
period of one second. Thus, the memorization can be implemented using a
fixed size array, retraining the association between a time, a list of
\emph{Events}, and a \emph{State}. Thanks to a careful use of immutable
lists to store \emph{Events}, querying the cache can be done using
reference equality for maximum efficiency.

\chapter{A Real-Time Multiplayer
Game}\label{a-real-time-multiplayer-game}

\TODO{This section...}

\section{Scala Remake of a Commodore 64
Game}\label{scala-remake-of-a-commodore-64-game}

There seems to be a tradition of using Scala.js to build games. Indeed,
at the time of writing, half of the projects listed on the official web
site of the project are video games. What could be better than a
multiplayer game to showcase the scala-js-transport library? To cope
with time constraints and stay focused on the project topic, the
decision was made to start working from an existing game. Out of the
list of open source games published on GitHub \cite{githubgames},
Survivor \cite{survivor2012} appears to be the most suitable for the
addition of real-time multiplayer features.

The original version of the game was written in 1982 for the Atari 2600.
One year later, a remake with better graphics is released for the
Commodore 64. Recently, S. Schiller developed an open source remake of
the game using HTML/CSS/JavaScript \cite{survivor2012}. This latest open
source remake served as a basis for the version of the game presented in
this chapter. The code was rewritten from scratch in Scala to follow the
functional programming style required by the scala-lag-comp framework,
but still shares the visual assets created by S. Schiller.

\section{Architecture}\label{architecture}

The Scala remake of Survivor puts together the scala-js-transport
library and the scala-lag-comp framework into a cross platform, real
time multiplayer game. On the networking side, it uses WebRTC if
available, and fallbacks to WebSocket otherwise.

Every aspect of the game logic is written in pure Scala, and is cross
compiled to run on both Java Virtual Machines and JavaScript engines.
Some IO related code had to be written specifically for each platform,
such as the handling of keyboard events and of rendering requests. The
JavaScript implementation is using the DOM APIs, and the JVM
implementation is built on top of the JavaFX/ScalaFX platform. On the
JavaScript side rendering requests are issued with
\emph{requestAnimationFrame}, which saves CPU usage by only requesting
rendering when the page is visible to the user.

In order to reuse the visual assets from \cite{survivor2012}, the JVM
version embeds a full WebKit browser in order to run the same
implementation of the user interface than the JavaScript version. The
rendering on the JVM goes as follows. It begins with \emph{render}
method being called with a \emph{State} to display. This \emph{State} is
serialized using the uPickle serialization library \cite{upickle}, and
passed to the embedded web browser as the argument of a
\emph{renderString} function. This function, defined in the Scala.js
with a \emph{@JSExport} annotation to be visible to the outside word,
deserializes it's argument back into a \emph{State}, but this time on
the JavaScript engine. With this trick, a \emph{State} can be transfered
from a JVM to a JavaScript engine, allowing the implementation of the
user interface to be shared between two platforms. While sufficient for
a proof of concept, this approach reduces the performances of the JVM
version of the game, which could be avoided with an actual rewrite of
the user interface on top of JavaFX/ScalaFX.

\section{Functional Graphical User Interface With
React}\label{functional-graphical-user-interface-with-react}

In this section we discuss the implementation of the graphics user
interface of our game using the React library \cite{react}. In
functional programing, the \emph{de facto} standard to building graphics
user interface seems to be functional reactive programing. React enables
a different approach\footnote{React supports a variety of architectures
  to build user interfaces, and is not limited the approach described in
  this section. For example, it is possible to store mutable state into
  \emph{Components}. React also supports server side rendering; by
  sharing the definition of \emph{Components} between client and server
  side, rendering can take place on the server, thus limiting the client
  work to reception and application of diffs.}, which suits perfectly
the architecture of the scala-lag-comp framework.

The interface is a single \emph{render} function, which takes as
argument the entire state of the application, and returns a complete
HTML representation of the state as a result.

The key performance aspect of React is that the library does directly
uses the DOM returned by the \emph{render} function. Instead of
replacing the content of the page whenever a new DOM is computed, React
computes a diff between this new DOM and the currently rendered DOM.
This diff is then used to do the send the minimal set of mutations to
the browser, thereby minimizing rendering time.

In order to lighten the diff computation, React uses \emph{Components},
small building block to define the \emph{render} function. A
\emph{Component} is essentially a fraction of the \emph{render}
function, given a subset of the application state it returns an HTML
representation for this subset of the application. \emph{Components} can
be composed into a tree that takes the complete application state at
it's root, and propagates the necessary elements of state thought the
tree, thus forming a complete rendering function of the application.
Thanks to this subdivision into small \emph{Components}, React is able
to optimize the diff operation by skipping branches of the HTML DOM
corresponding to \emph{Components} that depend on subsets of the state
which is unchanged since the last rendering.

There is a special optimization possible when working with immutable
data structure, as it is the case with the scala-lag-comp framework.
This optimization consists in overriding React's method for dirty
checking \emph{Components}. Instead of using deep equality on subsets of
states to determine if a \emph{Component} needs to be re-rendered, one
can use reference equality, which is a sufficient condition for equality
when working with immutable data structure.

\section{Experimental Result}\label{experimental-result}

\begin{itemize}
\item
  Reader are invited to try out the game! . To start a game, open the
  page trice and start moving around with arrow keys, and fire with
  space bar.
\item
  Screenshot
\item
  Server hosted on Amazon EC2 (via Heroku), on cross Atlantic server to
  test with bad network conditions.
\item
  60FPS on both platforms, lag free gameplay
\item
  JVM version feels slower, probably due the WebKit embedding into
  JavaFx.
\item
  Can feel some JVM "warm up" effect
\item
  Lag Compensation in action (frame by frame Screenshots)
\end{itemize}

\chapter{Related Work}\label{related-work}

\TODO{This Section...}

\section{Network libraries}\label{network-libraries}

The Node.js platform gained a lot of popularity in the recent year. By
enabling server-side of applications to be written in JavaScript, it
allows data structure and API can be shared between client and server.
In the case of network capabilities, many JavaScript libraries imitate
the WebSocket API and rely on \emph{duck typing} to share code between
client and server. For example, the ws library \cite{nodejsws} is an
implantation of WebSocket client and server for Node.js which provide
\emph{ws} objects behaving exactly like \emph{WebSocket} objects do on
the browser side. Similarly, SockJS clients (discussed in
\autoref{sockjs}) provide \emph{SockJS} objects that are almost drop in
replacement for \emph{WebSocket} objects. Finally, we could also mention
official WebRTC API \cite{webrtc2014}, which was designed such that its
"API for sending and receiving data models the behavior of WebSockets".

ClojureScript, the official Clojure to JavaScript compiler, has a large
ecosystem of libraries for both client and server, out of which Sente
\cite{sente} seems to be the most popular library for network
communication. It goals are similar to those of scala-js-transport,
offer a uniform client/server API which supports several transport
mechanism. Instead of using an existing WebSocket emulation library,
Sente implements its own solution to fallback on Ajax/long-polling when
WebSocket is not available.

With the large number of languages that compile to JavaScript
\cite{compiletojs}, an exhaustive coverage of the network libraries
would be beyond the scope of this report. To the best of our knowledge,
scala-js-transport is the first library offering this variety of
supported protocols and platform (summarized in \autoref{impl-summary}).

\section{Game Engines}\label{game-engines}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  AoE/Sc2
\item
  \cite{maphacks2011}
\item
  \cite{timelines2013}
\item
  \cite{elmlang}
\end{itemize}

\section{Functional Programming In
Games}\label{functional-programming-in-games}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Pong Async
  \url{http://ragnard.github.io/2013/10/01/clojurecup-pong-async.html}
\item
  \cite{retrogames2008}
\item
  \cite{lazysimulation2014}
\end{itemize}

\chapter{Conclusion and Future Work}\label{conclusion-and-future-work}

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Web workers
\item
  scalaz-stream/akka-stream wrappers
\item
  More utilities on top of Transport
\end{itemize}
